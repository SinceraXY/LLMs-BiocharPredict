{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "微调开源大模型llama3.1-8B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练集+验证集json格式文件准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data JSON file has been generated at: 训练集+验证集分类\\train_data2222.json\n",
      "Validation data JSON file has been generated at: 训练集+验证集分类\\validation_data2222.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "# List of file names based on the files you specified\n",
    "file_names = [\n",
    "    \"Ash + CHNO.csv\", \"Ash.csv\", \"CHNO.csv\", \"grain size.csv\", \"pH.csv\",\n",
    "    \"specific surface area + Ash + CHNO + pH + grain size.csv\",\n",
    "    \"specific surface area + pH + grain size.csv\", \"specific surface area.csv\",\n",
    "    \"yield + Ash + CHNO.csv\", \"yield + specific surface area + Ash + CHNO + pH + grain size.csv\",\n",
    "    \"yield + specific surface area + pH + grain size.csv\", \"yield.csv\"\n",
    "]\n",
    "\n",
    "# Set the directory path where files are located\n",
    "data_dir = \"训练集+验证集分类\"  # Adjust to your dataset directory\n",
    "train_data = []\n",
    "validation_data = []\n",
    "\n",
    "def generate_prediction_statement(file_name):\n",
    "    properties = {\n",
    "        \"yield\": \"yield\",\n",
    "        \"specific surface area\": \"specific surface area\",\n",
    "        \"Ash\": \"ash content\",\n",
    "        \"CHNO\": \"chemical composition\",\n",
    "        \"pH\": \"pH\",\n",
    "        \"grain size\": \"grain size\"\n",
    "    }\n",
    "    predicted_properties = [properties[key] for key in properties if key in file_name]\n",
    "    if predicted_properties:\n",
    "        if len(predicted_properties) > 1:\n",
    "            properties_list = \", \".join(predicted_properties[:-1]) + \" and \" + predicted_properties[-1]\n",
    "        else:\n",
    "            properties_list = predicted_properties[0]\n",
    "        return f\"Based on the above information, infer the biochar's {properties_list}.\"\n",
    "    else:\n",
    "        return \"Based on the above information, infer the biochar's properties.\"\n",
    "\n",
    "def create_json_data(df, file_name):\n",
    "    root_entries = []\n",
    "    for index, row in df.iterrows():\n",
    "        instruction_base = (\n",
    "            f\"The biomass resource used here is: {row.get('Biomass resources', '')}, sourced from: {row.get('Raw material sources', '')}, \"\n",
    "            f\"pre-treatment method is: {row.get('Pre-processing methods', '')}, preparation equipment used is: {row.get('Preparation equipment', '')}, \"\n",
    "            f\"other treatments include: {row.get('Other processing', '')}, modification related information: {row.get('modified', '')}, \"\n",
    "            f\"the cellulose content by weight percentage in the raw material is: {row.get('Cellulose content', '')}, \"\n",
    "            f\"hemicellulose content by weight percentage is: {row.get('Hemicellulose content', '')}, \"\n",
    "            f\"lignin content by weight percentage is: {row.get('Lignin content', '')}, \"\n",
    "            f\"ash content by weight percentage is: {row.get('Ash content', '')}, \"\n",
    "            f\"fixed carbon content by weight percentage is: {row.get('Fixed carbon content', '')}, \"\n",
    "            f\"volatile matter content by weight percentage is: {row.get('Volatile matter content', '')}, \"\n",
    "            f\"carbon content by weight percentage is: {row.get('Carbon content', '')}, \"\n",
    "            f\"hydrogen content by weight percentage is: {row.get('Hydrogen content', '')}, \"\n",
    "            f\"nitrogen content by weight percentage is: {row.get('Nitrogen content', '')}, \"\n",
    "            f\"oxygen content by weight percentage is: {row.get('Oxygen content', '')}, \"\n",
    "            f\"sulfur content by weight percentage is: {row.get('Sulfur content', '')}, \"\n",
    "            f\"kalium content by weight percentage is: {row.get('Kalium content', '')}, \"\n",
    "            f\"calcium content by weight percentage is: {row.get('Calcium content', '')}, \"\n",
    "            f\"sodium content by weight percentage is: {row.get('Natrium content', '')}, \"\n",
    "            f\"magnesium content by weight percentage is: {row.get('Magnesium content', '')}, \"\n",
    "            f\"ferrum content by weight percentage is: {row.get('Ferrum content', '')}, \"\n",
    "            f\"silicon content by weight percentage is: {row.get('Silicon content', '')}, \"\n",
    "            f\"the maximum treatment temperature in the pyrolysis experiment is: {row.get('Highest treatment temperature', '')}℃, \"\n",
    "            f\"heating rate is: {row.get('Heating rate', '')}℃/min, \"\n",
    "            f\"holding time is: {row.get('Residence time', '')} min.\"\n",
    "        )\n",
    "        #prediction_statement = generate_prediction_statement(file_name)\n",
    "        #instruction = instruction_base + \" \" + prediction_statement\n",
    "        instruction = instruction_base\n",
    "        prediction_statement = generate_prediction_statement(file_name)\n",
    "\n",
    "        output_parts = []\n",
    "        if \"yield\" in file_name:\n",
    "            output_parts.append(f\"yield by weight percentage is {row.get('Biochar yield', '')}\")\n",
    "        if \"specific surface area\" in file_name:\n",
    "            output_parts.append(f\"specific surface area is {row.get('specific surface area', '')} m²/g\")\n",
    "        if \"Ash\" in file_name:\n",
    "            output_parts.append(f\"ash content by weight percentage is {row.get('Ash content of the product', '')}\")\n",
    "        if \"CHNO\" in file_name:\n",
    "            chno_parts = [\n",
    "                f\"carbon content is {row.get('Carbon content of the product', '')}\",\n",
    "                f\"hydrogen content is {row.get('Hydrogen content of the product', '')}\",\n",
    "                f\"nitrogen content is {row.get('Nitrogen content of products', '')}\",\n",
    "                f\"oxygen content is {row.get('Oxygen content of products', '')}\"\n",
    "            ]\n",
    "            output_parts.append(\", \".join(chno_parts[:-1]) + \" and \" + chno_parts[-1])\n",
    "        if \"pH\" in file_name:\n",
    "            output_parts.append(f\"pH is {row.get('pH', '')}\")\n",
    "        if \"grain size\" in file_name:\n",
    "            output_parts.append(f\"grain size is {row.get('grain size', '')} mm\")\n",
    "\n",
    "        if output_parts:\n",
    "            if len(output_parts) == 1:\n",
    "                output = f\"The prepared biochar {output_parts[0]}.\"\n",
    "            else:\n",
    "                output = f\"The prepared biochar has {', '.join(output_parts[:-1])} and {output_parts[-1]}.\"\n",
    "        else:\n",
    "            output = \"The prepared biochar has no relevant information.\"\n",
    "\n",
    "        root_entries.append({\n",
    "            \"instruction\": instruction,\n",
    "            \"input\": prediction_statement,\n",
    "            \"output\": output\n",
    "        })\n",
    "    return root_entries\n",
    "\n",
    "# Read each file and split the data into training and testing sets\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            data_entries = create_json_data(df, file_name)\n",
    "            random.shuffle(data_entries)  # Shuffle the entries\n",
    "            split_index = int(0.7 * len(data_entries))  # Calculate the split index\n",
    "            train_data.extend(data_entries[:split_index])\n",
    "            validation_data.extend(data_entries[split_index:])\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"{file_name} does not exist in the directory.\")\n",
    "\n",
    "# Write the training data to a JSON file\n",
    "train_json_file_path = os.path.join(data_dir, 'train_data2222.json')\n",
    "with open(train_json_file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Write the validation data to a JSON file\n",
    "validation_json_file_path = os.path.join(data_dir, 'validation_data2222.json')\n",
    "with open(validation_json_file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(validation_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Print paths of the created JSON files\n",
    "print(f\"Training data JSON file has been generated at: {train_json_file_path}\")\n",
    "print(f\"Validation data JSON file has been generated at: {validation_json_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集json格式文件准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data JSON file has been generated at: 测试集分类\\test_data.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# List of file names based on the files you specified\n",
    "file_names = [\n",
    "    \"Ash + CHNO.csv\", \"Ash.csv\", \"CHNO.csv\", \"grain size.csv\", \"pH.csv\",\n",
    "    \"specific surface area + Ash + CHNO + pH + grain size.csv\",\n",
    "    \"specific surface area + pH + grain size.csv\", \"specific surface area.csv\",\n",
    "    \"yield + Ash + CHNO.csv\", \"yield + specific surface area + Ash + CHNO + pH + grain size.csv\",\n",
    "    \"yield + specific surface area + pH + grain size.csv\", \"yield.csv\"\n",
    "]\n",
    "\n",
    "# Set the directory path where files are located\n",
    "data_dir = \"测试集分类\"  # Adjust to your dataset directory\n",
    "test_data = []\n",
    "\n",
    "def generate_prediction_statement(file_name):\n",
    "    properties = {\n",
    "        \"yield\": \"yield\",\n",
    "        \"specific surface area\": \"specific surface area\",\n",
    "        \"Ash\": \"ash content\",\n",
    "        \"CHNO\": \"chemical composition\",\n",
    "        \"pH\": \"pH\",\n",
    "        \"grain size\": \"grain size\"\n",
    "    }\n",
    "    predicted_properties = [properties[key] for key in properties if key in file_name]\n",
    "    if predicted_properties:\n",
    "        if len(predicted_properties) > 1:\n",
    "            properties_list = \", \".join(predicted_properties[:-1]) + \" and \" + predicted_properties[-1]\n",
    "        else:\n",
    "            properties_list = predicted_properties[0]\n",
    "        return f\"Based on the above information, infer the biochar's {properties_list}.\"\n",
    "    else:\n",
    "        return \"Based on the above information, infer the biochar's properties.\"\n",
    "\n",
    "def create_json_data(df, file_name):\n",
    "    root_entries = []\n",
    "    for index, row in df.iterrows():\n",
    "        instruction_base = (\n",
    "            f\"The biomass resource used here is: {row.get('Biomass resources', '')}, sourced from: {row.get('Raw material sources', '')}, \"\n",
    "            f\"pre-treatment method is: {row.get('Pre-processing methods', '')}, preparation equipment used is: {row.get('Preparation equipment', '')}, \"\n",
    "            f\"other treatments include: {row.get('Other processing', '')}, modification related information: {row.get('modified', '')}, \"\n",
    "            f\"the cellulose content by weight percentage in the raw material is: {row.get('Cellulose content', '')}, \"\n",
    "            f\"hemicellulose content by weight percentage is: {row.get('Hemicellulose content', '')}, \"\n",
    "            f\"lignin content by weight percentage is: {row.get('Lignin content', '')}, \"\n",
    "            f\"ash content by weight percentage is: {row.get('Ash content', '')}, \"\n",
    "            f\"fixed carbon content by weight percentage is: {row.get('Fixed carbon content', '')}, \"\n",
    "            f\"volatile matter content by weight percentage is: {row.get('Volatile matter content', '')}, \"\n",
    "            f\"carbon content by weight percentage is: {row.get('Carbon content', '')}, \"\n",
    "            f\"hydrogen content by weight percentage is: {row.get('Hydrogen content', '')}, \"\n",
    "            f\"nitrogen content by weight percentage is: {row.get('Nitrogen content', '')}, \"\n",
    "            f\"oxygen content by weight percentage is: {row.get('Oxygen content', '')}, \"\n",
    "            f\"sulfur content by weight percentage is: {row.get('Sulfur content', '')}, \"\n",
    "            f\"kalium content by weight percentage is: {row.get('Kalium content', '')}, \"\n",
    "            f\"calcium content by weight percentage is: {row.get('Calcium content', '')}, \"\n",
    "            f\"sodium content by weight percentage is: {row.get('Natrium content', '')}, \"\n",
    "            f\"magnesium content by weight percentage is: {row.get('Magnesium content', '')}, \"\n",
    "            f\"ferrum content by weight percentage is: {row.get('Ferrum content', '')}, \"\n",
    "            f\"silicon content by weight percentage is: {row.get('Silicon content', '')}, \"\n",
    "            f\"the maximum treatment temperature in the pyrolysis experiment is: {row.get('Highest treatment temperature', '')}℃, \"\n",
    "            f\"heating rate is: {row.get('Heating rate', '')}℃/min, \"\n",
    "            f\"holding time is: {row.get('Residence time', '')} min.\"\n",
    "        )\n",
    "        prediction_statement = generate_prediction_statement(file_name)\n",
    "        instruction = instruction_base + \" \" + prediction_statement\n",
    "\n",
    "        output_parts = []\n",
    "        if \"yield\" in file_name:\n",
    "            output_parts.append(f\"yield by weight percentage is {row.get('Biochar yield', '')}\")\n",
    "        if \"specific surface area\" in file_name:\n",
    "            output_parts.append(f\"specific surface area is {row.get('specific surface area', '')} m²/g\")\n",
    "        if \"Ash\" in file_name:\n",
    "            output_parts.append(f\"ash content by weight percentage is {row.get('Ash content of the product', '')}\")\n",
    "        if \"CHNO\" in file_name:\n",
    "            chno_parts = [\n",
    "                f\"carbon content is {row.get('Carbon content of the product', '')}\",\n",
    "                f\"hydrogen content is {row.get('Hydrogen content of the product', '')}\",\n",
    "                f\"nitrogen content is {row.get('Nitrogen content of products', '')}\",\n",
    "                f\"oxygen content is {row.get('Oxygen content of products', '')}\"\n",
    "            ]\n",
    "            output_parts.append(\", \".join(chno_parts[:-1]) + \" and \" + chno_parts[-1])\n",
    "        if \"pH\" in file_name:\n",
    "            output_parts.append(f\"pH is {row.get('pH', '')}\")\n",
    "        if \"grain size\" in file_name:\n",
    "            output_parts.append(f\"grain size is {row.get('grain size', '')} mm\")\n",
    "\n",
    "        if output_parts:\n",
    "            if len(output_parts) == 1:\n",
    "                output = f\"The prepared biochar {output_parts[0]}.\"\n",
    "            else:\n",
    "                output = f\"The prepared biochar has {', '.join(output_parts[:-1])} and {output_parts[-1]}.\"\n",
    "        else:\n",
    "            output = \"The prepared biochar has no relevant information.\"\n",
    "\n",
    "        root_entries.append({\n",
    "            \"instruction\": instruction,\n",
    "            \"input\": \"\",\n",
    "            \"output\": output\n",
    "        })\n",
    "    return root_entries\n",
    "\n",
    "# Read each file and gather all data into a single dataset\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            data_entries = create_json_data(df, file_name)\n",
    "            test_data.extend(data_entries)  # Add all entries to the test dataset\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"{file_name} does not exist in the directory.\")\n",
    "\n",
    "# Write the complete test data to a JSON file\n",
    "test_json_file_path = os.path.join(data_dir, 'test_data.json')\n",
    "with open(test_json_file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(test_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Print path of the created JSON file\n",
    "print(f\"Test data JSON file has been generated at: {test_json_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
